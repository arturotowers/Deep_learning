{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_1"
      },
      "outputs": [],
      "source": [
        "import os, glob, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "from wandb.integration.keras import WandbCallback\n",
        "import gc\n",
        "\n",
        "# Decorador para que Hugging Face/Keras reconozcan la función\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def calc_mvd(real_images, gen_images):\n",
        "    \"\"\"\n",
        "    Calcula la distancia entre medias y desviaciones estándar (Mean-Variance Distance)\n",
        "    entre un conjunto de imágenes reales y otro de imágenes generadas.\n",
        "    \"\"\"\n",
        "    real_flat = real_images.reshape(real_images.shape[0], -1)\n",
        "    gen_flat = gen_images.reshape(gen_images.shape[0], -1)\n",
        "    mean_real = np.mean(real_flat, axis=0)\n",
        "    std_real = np.std(real_flat, axis=0)\n",
        "    mean_gen = np.mean(gen_flat, axis=0)\n",
        "    std_gen = np.std(gen_flat, axis=0)\n",
        "    mean_distance = np.linalg.norm(mean_real - mean_gen)\n",
        "    std_distance = np.linalg.norm(std_real - std_gen)\n",
        "    return mean_distance + std_distance\n",
        "\n",
        "# Callback para loguear MVD al final de cada época\n",
        "class MVDEpochCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, real_data, decoder, latent_dim, label_prefix=\"Train\"):\n",
        "        super().__init__()\n",
        "        self.real_data = real_data\n",
        "        self.decoder = decoder\n",
        "        self.latent_dim = latent_dim\n",
        "        self.label_prefix = label_prefix\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Generar muestras aleatorias en el espacio latente\n",
        "        z_samples = np.random.normal(size=(len(self.real_data), self.latent_dim))\n",
        "        gen_images = self.decoder.predict(z_samples)\n",
        "        # Calcular MVD entre las imágenes reales y generadas\n",
        "        mvd_value = calc_mvd(self.real_data, gen_images)\n",
        "        # Loguear en W&B\n",
        "        wandb.log({f\"MVD_{self.label_prefix}\": mvd_value, \"epoch\": epoch})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_5"
      },
      "outputs": [],
      "source": [
        "# Rutas base\n",
        "base_path = \"/content/Deep_learning/Proyecto 1 - DAE + VAE/processed_dataset\"\n",
        "train_path = os.path.join(base_path, \"train\")\n",
        "val_path   = os.path.join(base_path, \"val\")\n",
        "test_path  = os.path.join(base_path, \"test\")\n",
        "\n",
        "# Obtener las rutas de las imágenes para cada categoría\n",
        "train_paths_botellas = glob.glob(train_path + \"/botella_de_vidrio/*.npy\")\n",
        "train_paths_relojes  = glob.glob(train_path + \"/reloj_de_pared_circular_clasico/*.npy\")\n",
        "\n",
        "val_paths_botellas   = glob.glob(val_path + \"/botella_de_vidrio/*.npy\")\n",
        "val_paths_relojes    = glob.glob(val_path + \"/reloj_de_pared_circular_clasico/*.npy\")\n",
        "\n",
        "test_paths_botellas  = glob.glob(test_path + \"/botella_de_vidrio/*.npy\")\n",
        "test_paths_relojes   = glob.glob(test_path + \"/reloj_de_pared_circular_clasico/*.npy\")\n",
        "\n",
        "# Cargar las imágenes para cada categoría\n",
        "X_train_botellas = np.array([np.load(p) for p in train_paths_botellas])\n",
        "X_train_relojes  = np.array([np.load(p) for p in train_paths_relojes])\n",
        "\n",
        "X_val_botellas   = np.array([np.load(p) for p in val_paths_botellas])\n",
        "X_val_relojes    = np.array([np.load(p) for p in val_paths_relojes])\n",
        "\n",
        "X_test_botellas  = np.array([np.load(p) for p in test_paths_botellas])\n",
        "X_test_relojes   = np.array([np.load(p) for p in test_paths_relojes])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_6"
      },
      "outputs": [],
      "source": [
        "print(\"Botellas - Train:\", X_train_botellas.shape, \"Val:\", X_val_botellas.shape, \"Test:\", X_test_botellas.shape)\n",
        "print(\"Relojes - Train:\", X_train_relojes.shape, \"Val:\", X_val_relojes.shape, \"Test:\", X_test_relojes.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_7"
      },
      "outputs": [],
      "source": [
        "# Semilla para reproducibilidad\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# Definir tamaño de imagen\n",
        "IMG_SIZE = 256  # Ajusta según tu dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, Model, Input\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "class VAE(Model):\n",
        "    def __init__(self, encoder, decoder, img_size=IMG_SIZE, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.img_size = img_size\n",
        "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker, self.reconstruction_loss_tracker, self.kl_loss_tracker]\n",
        "\n",
        "    def vae_loss(self, y_true, y_pred, z_mean, z_log_var):\n",
        "        reconstruction_loss = tf.keras.losses.mse(K.flatten(y_true), K.flatten(y_pred))\n",
        "        reconstruction_loss *= self.img_size * self.img_size * 3\n",
        "        kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "        kl_loss = -0.5 * tf.reduce_mean(kl_loss)\n",
        "        return reconstruction_loss + kl_loss\n",
        "\n",
        "    def train_step(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            loss = self.vae_loss(data, reconstruction, z_mean, z_log_var)\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.loss_tracker.update_state(loss)\n",
        "\n",
        "        # Aquí, para no sobreescribir kl_loss, podrías calcularlo aparte si lo quisieras exacto.\n",
        "        # Pero en este ejemplo, se actualiza la reconstrucción y KL por separado de forma aproximada.\n",
        "        # Lo importante es que en logs se vea la métrica final.\n",
        "        recon_loss_value = reconstruction_loss = tf.keras.losses.mse(\n",
        "            K.flatten(data), K.flatten(reconstruction)\n",
        "        ) * (self.img_size * self.img_size * 3)\n",
        "        kl_value = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "        kl_value = -0.5 * tf.reduce_mean(kl_value)\n",
        "\n",
        "        self.reconstruction_loss_tracker.update_state(recon_loss_value)\n",
        "        self.kl_loss_tracker.update_state(kl_value)\n",
        "\n",
        "        return {\n",
        "            \"loss\": self.loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z = self.encoder(inputs)[2]\n",
        "        reconstructed = self.decoder(z)\n",
        "        return reconstructed\n",
        "\n",
        "def build_vae(latent_dim, img_size=IMG_SIZE):\n",
        "    # --- Encoder ---\n",
        "    encoder_inputs = Input(shape=(img_size, img_size, 3))\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding='same', activation='relu')(encoder_inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, 3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(128, 3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(256, 3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(1024, activation='relu')(x)\n",
        "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "\n",
        "    def sampling(args):\n",
        "        z_mean, z_log_var = args\n",
        "        epsilon = tf.random.normal(shape=tf.shape(z_mean), seed=42)\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    z = layers.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "    encoder = Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "\n",
        "    # --- Decoder ---\n",
        "    latent_inputs = Input(shape=(latent_dim,))\n",
        "    x = layers.Dense((img_size // 16) * (img_size // 16) * 256, activation='relu')(latent_inputs)\n",
        "    x = layers.Reshape((img_size // 16, img_size // 16, 256))(x)\n",
        "    x = layers.Conv2DTranspose(256, 3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(128, 3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(32, 3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    decoder_outputs = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    decoder = Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "    vae = VAE(encoder, decoder, img_size=img_size)\n",
        "    return vae, encoder, decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_9"
      },
      "outputs": [],
      "source": [
        "# Instanciar y compilar los VAEs para cada clase\n",
        "LATENT_DIM = 256\n",
        "\n",
        "# VAE para Botellas\n",
        "vae_bottle, encoder_bottle, decoder_bottle = build_vae(LATENT_DIM, img_size=IMG_SIZE)\n",
        "optimizer_bottle = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "vae_bottle.compile(optimizer=optimizer_bottle, loss=tf.keras.losses.mse)\n",
        "\n",
        "# VAE para Relojes\n",
        "vae_clock, encoder_clock, decoder_clock = build_vae(LATENT_DIM, img_size=IMG_SIZE)\n",
        "optimizer_clock = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "vae_clock.compile(optimizer=optimizer_clock, loss=tf.keras.losses.mse)\n",
        "\n",
        "vae_bottle.summary()\n",
        "vae_clock.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_10"
      },
      "outputs": [],
      "source": [
        "# Login a wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_11"
      },
      "outputs": [],
      "source": [
        "# Definir ruta donde se guardarán los modelos\n",
        "models_path = \"/content/Deep_learning/Proyecto 1 - DAE + VAE/Models\"\n",
        "os.makedirs(models_path, exist_ok=True)\n",
        "\n",
        "# Entrenamiento VAE Botellas\n",
        "run_bottle = wandb.init(entity=\"arturo-torres-iteso\", project=\"VAE + DAE\", name=\"VAE_bottles_Arturo\", reinit=True)\n",
        "\n",
        "history_bottle = vae_bottle.fit(\n",
        "    X_train_botellas,\n",
        "    X_train_botellas,\n",
        "    epochs=10,            # Ajusta las épocas\n",
        "    batch_size=4,\n",
        "    validation_data=(X_val_botellas, X_val_botellas),\n",
        "    callbacks=[\n",
        "        WandbCallback(save_model=False),\n",
        "        MVDEpochCallback(X_train_botellas, decoder_bottle, LATENT_DIM, label_prefix=\"Bottles\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Definir ruta completa para guardar el modelo de botellas\n",
        "model_save_path_bottle = os.path.join(models_path, \"vae_bottle_model_Arturo.keras\")\n",
        "vae_bottle.save(model_save_path_bottle)\n",
        "wandb.save(model_save_path_bottle)\n",
        "wandb.finish()\n",
        "\n",
        "# Liberar memoria\n",
        "tf.keras.backend.clear_session()\n",
        "gc.collect()\n",
        "\n",
        "# Entrenamiento VAE Relojes\n",
        "run_clock = wandb.init(project=\"VAE + DAE\", name=\"VAE_Clock_Arturo\", reinit=True)\n",
        "\n",
        "history_clock = vae_clock.fit(\n",
        "    X_train_relojes,\n",
        "    X_train_relojes,\n",
        "    epochs=10,\n",
        "    batch_size=4,\n",
        "    validation_data=(X_val_relojes, X_val_relojes),\n",
        "    callbacks=[\n",
        "        WandbCallback(save_model=False),\n",
        "        MVDEpochCallback(X_train_relojes, decoder_clock, LATENT_DIM, label_prefix=\"Clocks\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Definir ruta completa para guardar el modelo de relojes\n",
        "model_save_path_clock = os.path.join(models_path, \"vae_clock_model_Arturo.keras\")\n",
        "vae_clock.save(model_save_path_clock)\n",
        "wandb.save(model_save_path_clock)\n",
        "wandb.finish()\n",
        "\n",
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_12"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de evaluación posterior con la métrica MVD en test\n",
        "run_eval = wandb.init(project=\"VAE + DAE\", name=\"Evaluation_MVD\", reinit=True)\n",
        "\n",
        "def evaluate_mvd(decoder, real_data, latent_dim, label_prefix):\n",
        "    n_samples = len(real_data)\n",
        "    z_samples = np.random.normal(size=(n_samples, latent_dim))\n",
        "    gen_images = decoder.predict(z_samples)\n",
        "    mvd_val = calc_mvd(real_data, gen_images)\n",
        "    print(f\"{label_prefix} VAE - MVD: {mvd_val:.2f}\")\n",
        "    wandb.log({f\"MVD_{label_prefix}_test\": mvd_val})\n",
        "\n",
        "# Cargamos los modelos (si fuera un nuevo entorno, harías load_model con custom_objects)\n",
        "# vae_bottle_loaded = tf.keras.models.load_model(\"vae_bottle_model_Arturo.keras\", custom_objects={\"calc_mvd\": calc_mvd, \"VAE\": VAE})\n",
        "# O en el mismo notebook simplemente reusas \"decoder_bottle\".\n",
        "\n",
        "# Evaluación en test\n",
        "evaluate_mvd(decoder_bottle, X_test_botellas, LATENT_DIM, \"Bottle\")\n",
        "evaluate_mvd(decoder_clock, X_test_relojes, LATENT_DIM, \"Clock\")\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_13"
      },
      "outputs": [],
      "source": [
        "# Visualización de algunas imágenes generadas\n",
        "def display_generated_images(gen_images, title):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    n = min(5, gen_images.shape[0])\n",
        "    for i in range(n):\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(gen_images[i])\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "# Generar imágenes con el decoder de botellas\n",
        "z_samples_bottle = np.random.normal(size=(5, LATENT_DIM))\n",
        "gen_images_bottle = decoder_bottle.predict(z_samples_bottle)\n",
        "display_generated_images(gen_images_bottle, \"Generated Images - Bottle VAE\")\n",
        "\n",
        "# Generar imágenes con el decoder de relojes\n",
        "z_samples_clock = np.random.normal(size=(5, LATENT_DIM))\n",
        "gen_images_clock = decoder_clock.predict(z_samples_clock)\n",
        "display_generated_images(gen_images_clock, \"Generated Images - Clock VAE\")\n",
        "\n",
        "# Log en W&B\n",
        "run_vis = wandb.init(project=\"VAE + DAE\", name=\"Generated_Images\", reinit=True)\n",
        "wandb.log({\n",
        "    \"Generated_Images_Bottle\": [wandb.Image(img) for img in gen_images_bottle[:5]],\n",
        "    \"Generated_Images_Clock\": [wandb.Image(img) for img in gen_images_clock[:5]]\n",
        "})\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "VAE_CustomMetric_MVD.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
